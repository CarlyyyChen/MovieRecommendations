{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Sc2sxLeRtfQK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MSLxp50tfQN",
    "outputId": "fc33324c-6d7d-4c6f-b169-8a0208082b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\dell\\Desktop\\CS 5100 FAI\\Final project\\MovieRecommendations\\src\\neural_collaborative_filtering\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-xEhhE5GmNZ"
   },
   "source": [
    "## NCF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPLB0pQUG1ZQ"
   },
   "source": [
    "### Custom Dataset for NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g3RtRgfVG1ZR"
   },
   "outputs": [],
   "source": [
    "class NCFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, user_ids, movie_ids, ratings):\n",
    "        self.user_ids = torch.tensor(user_ids.to_numpy(), dtype=torch.long)\n",
    "        self.movie_ids = torch.tensor(movie_ids.to_numpy(), dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings.to_numpy(), dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.movie_ids[idx], self.ratings[idx]\n",
    "\n",
    "    # Define the NCF model\n",
    "class NCFModel(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embed_dim):\n",
    "        super(NCFModel, self).__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, embed_dim)\n",
    "        self.movie_embedding = torch.nn.Embedding(num_movies, embed_dim)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embed_dim * 2, 8),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(8, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        movie_embeds = self.movie_embedding(movie_ids)\n",
    "        x = torch.cat([user_embeds, movie_embeds], dim=-1)\n",
    "        return self.fc(x).squeeze() * 4 + 1 # scale to [1,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUI-RYhuG1ZS"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fJof4OM3G1ZT"
   },
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, criterion, optimizer, epochs=5, k=5, device=None):\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for user_ids, movie_ids, ratings in data_loader:\n",
    "            # Move data to the same device as the model (GPU)\n",
    "            user_ids = user_ids.to(device)\n",
    "            movie_ids = movie_ids.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            # Zero the gradients, run the forward pass, compute loss, and backpropagate\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, movie_ids)\n",
    "            loss = criterion(outputs, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} | Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "    # Print the profiler results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK3ay4_HH2_F"
   },
   "source": [
    "## Validation with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIRd30PAtfQS"
   },
   "source": [
    "### Metrics for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PnCDtcOHtfQS"
   },
   "outputs": [],
   "source": [
    "def calculate_mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "epsrC25ItfQS"
   },
   "outputs": [],
   "source": [
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FOzooakIHvGI"
   },
   "outputs": [],
   "source": [
    "TOP_N = 5\n",
    "# MODEL_PATH = \"C:/Users/anujp/OneDrive/Desktop/MovieRecommendations/models/neural_collaborative_filtering/ncff_model.pkl\"  # Path to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JCLH-JJItfQU"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, k=TOP_N):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for user_ids, movie_ids, ratings in data_loader:\n",
    "            outputs = model(user_ids, movie_ids)\n",
    "            all_targets.extend(ratings.cpu().numpy())\n",
    "            all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    mae = calculate_mae(all_targets, all_predictions)\n",
    "    rmse = calculate_rmse(all_targets, all_predictions)\n",
    "\n",
    "    print(f\"Evaluation | MAE: {mae:.4f} | RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6b7Ylx4tfQV"
   },
   "source": [
    "## Recommend movies for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7QB9PJNVtfQV"
   },
   "outputs": [],
   "source": [
    "def recommend_movies(model, user_id, all_movie_ids, k=TOP_N):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        user_tensor = torch.tensor([user_id] * len(all_movie_ids), dtype=torch.long)\n",
    "        movie_tensor = torch.tensor(all_movie_ids, dtype=torch.long)\n",
    "        predictions = model(user_tensor, movie_tensor)\n",
    "    top_k_indices = predictions.argsort(descending=True)[:k]\n",
    "    return top_k_indices.numpy(), predictions[top_k_indices].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lYiazcI_tfQV"
   },
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    \"\"\"Prompt the user to input a user ID and select a model.\"\"\"\n",
    "    print(\"\\n--- Recommendation System ---\")\n",
    "    print(\"Enter 'q' at any time to quit.\")\n",
    "    user_id = input(\"Enter the User ID for recommendations (1-6040): \")\n",
    "    if user_id.strip().lower() == 'q':\n",
    "        return 'q'\n",
    "    while not user_id.isdigit() or not (1 <= int(user_id) <= 6040):\n",
    "        print(\"Invalid input. Please enter a numeric User ID between 1 and 6040 or 'q' to quit.\")\n",
    "        user_id = input(\"Enter the User ID for recommendations: \")\n",
    "        if user_id.strip().lower() == 'q':\n",
    "            return 'q'\n",
    "    return int(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r9fCxs1II-O"
   },
   "source": [
    "# Function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "v5_SjkCSII-P"
   },
   "outputs": [],
   "source": [
    "def save_model(model, data, model_path=\"../../models/neural_collaborative_filtering/ncf_model.pkl\"):\n",
    "    \"\"\"\n",
    "    Save model along with mappings at specified path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create directory path if it doesn't exist\n",
    "        directory = os.path.dirname(model_path)\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        # Create mappings for UserID and MovieID\n",
    "        user_mapping = dict(enumerate(data['UserID'].astype('category').cat.categories))\n",
    "        movie_mapping = dict(enumerate(data['MovieID'].astype('category').cat.categories))\n",
    "        \n",
    "        # Create save dictionary\n",
    "        save_dict = {\n",
    "            'model_state': model.state_dict(),\n",
    "            'user_mapping': user_mapping,\n",
    "            'movie_mapping': movie_mapping,\n",
    "            'model_config': {\n",
    "                'num_users': len(user_mapping),\n",
    "                'num_movies': len(movie_mapping),\n",
    "                'embed_dim': 60\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save everything to pickle file\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            pickle.dump(save_dict, f)\n",
    "        \n",
    "        print(f\"Model and mappings saved successfully to: {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLn7tAmQtfQV"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GtYkxriktfQV"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load and merge data\n",
    "    data = pd.read_csv('../../data/Final_data/Final_data.csv')\n",
    "\n",
    "    # Preprocessing: Convert UserID and MovieID to categorical codes\n",
    "    data['UserID'] = data['UserID'].astype('category').cat.codes\n",
    "    data['MovieID'] = data['MovieID'].astype('category').cat.codes\n",
    "\n",
    "    # Extract features for NCF\n",
    "    user_ids = data['UserID']\n",
    "    movie_ids = data['MovieID']\n",
    "    ratings = data['Rating']\n",
    "    titles = data['Title']\n",
    "\n",
    "    # Map MovieID to Title for quick access\n",
    "    movie_id_to_title = dict(zip(movie_ids, titles))\n",
    "\n",
    "    # Determine unique users and movies for embedding\n",
    "    num_users = user_ids.nunique()\n",
    "    num_movies = movie_ids.nunique()\n",
    "    embed_dim = 60\n",
    "\n",
    "    # Train-test split\n",
    "    user_train, user_test, movie_train, movie_test, rating_train, rating_test = train_test_split(\n",
    "        user_ids, movie_ids, ratings, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = NCFDataset(user_train, movie_train, rating_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    test_dataset = NCFDataset(user_test, movie_test, rating_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = NCFModel(num_users, num_movies, embed_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_model(model, train_loader, criterion, optimizer, epochs=10, k=5)\n",
    "    \n",
    "    # Save the model - UNCOMMENTED THIS LINE\n",
    "    save_model(model, data)\n",
    "    \n",
    "    evaluate_model(model, test_loader, k=TOP_N)\n",
    "\n",
    "    # Generate recommendations based on user input\n",
    "    while True:\n",
    "        user_id = get_user_input()\n",
    "        if user_id == 'q':\n",
    "            print(\"Exiting the Recommendation System!\")\n",
    "            break\n",
    "        unique_movie_ids = movie_ids.unique()\n",
    "        top_movies, predicted_ratings = recommend_movies(model, user_id, unique_movie_ids)\n",
    "        print(f\"\\nTop {TOP_N} recommended movies for User {user_id}:\")\n",
    "        for i, (movie, rating) in enumerate(zip(top_movies, predicted_ratings)):\n",
    "            movie_title = movie_id_to_title.get(movie, \"Unknown Movie\")\n",
    "            print(f\"{i + 1}: {movie_title}, Predicted Rating: {rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDlGGJgutfQV",
    "outputId": "9b376d97-30fc-4b8a-f1ed-8645f9447a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 1.1177\n",
      "Epoch 2 | Loss: 0.9022\n",
      "Epoch 3 | Loss: 0.8363\n",
      "Epoch 4 | Loss: 0.7837\n",
      "Epoch 5 | Loss: 0.7423\n",
      "Epoch 6 | Loss: 0.7098\n",
      "Epoch 7 | Loss: 0.6848\n",
      "Epoch 8 | Loss: 0.6629\n",
      "Epoch 9 | Loss: 0.6446\n",
      "Epoch 10 | Loss: 0.6305\n",
      "Model and mappings saved successfully to: ../../models/neural_collaborative_filtering/ncf_model.pkl\n",
      "Evaluation | MAE: 0.6811 | RMSE: 0.8927\n",
      "\n",
      "--- Recommendation System ---\n",
      "Enter 'q' at any time to quit.\n",
      "\n",
      "Top 5 recommended movies for User 9:\n",
      "1: The Intern (2015), Predicted Rating: 4.23\n",
      "2: Team America: World Police (2004), Predicted Rating: 4.20\n",
      "3: Spanish Apartment, The (L'auberge espagnole) (2002), Predicted Rating: 4.19\n",
      "4: City by the Sea (2002), Predicted Rating: 4.17\n",
      "5: Act of Killing, The (2012), Predicted Rating: 4.16\n",
      "\n",
      "--- Recommendation System ---\n",
      "Enter 'q' at any time to quit.\n",
      "\n",
      "Top 5 recommended movies for User 9:\n",
      "1: The Intern (2015), Predicted Rating: 4.23\n",
      "2: Team America: World Police (2004), Predicted Rating: 4.20\n",
      "3: Spanish Apartment, The (L'auberge espagnole) (2002), Predicted Rating: 4.19\n",
      "4: City by the Sea (2002), Predicted Rating: 4.17\n",
      "5: Act of Killing, The (2012), Predicted Rating: 4.16\n",
      "\n",
      "--- Recommendation System ---\n",
      "Enter 'q' at any time to quit.\n",
      "Exiting the Recommendation System!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-K4I0UW_B12",
    "outputId": "d1f20ef2-3139-4ff8-eae2-c40029742ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rated movies for User 9:\n",
      "       MovieID                                              Title  Rating\n",
      "1111     5902                                  Adaptation (2002)     5.0\n",
      "1082     1198  Raiders of the Lost Ark (Indiana Jones and the...     5.0\n",
      "1112     5952      Lord of the Rings: The Two Towers, The (2002)     5.0\n",
      "1089     2300                              Producers, The (1968)     5.0\n",
      "1103     5481                 Austin Powers in Goldmember (2002)     5.0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "merged_data = pd.read_csv('../../data/Final_data/Final_data.csv')\n",
    "\n",
    "# Function to get top 5 rated movies for a specific user ID\n",
    "def top_5_rated_movies(user_id, data):\n",
    "    # Filter the dataset for the given user ID\n",
    "    user_data = data[data['UserID'] == user_id]\n",
    "\n",
    "    # Sort the ratings in descending order\n",
    "    top_movies = user_data.sort_values(by='Rating', ascending=False).head(5)\n",
    "\n",
    "    # Return the top 5 rated movies\n",
    "    return top_movies[['MovieID', 'Title', 'Rating']]\n",
    "\n",
    "# Example: Fetch top 5 rated movies for User ID 6\n",
    "user_id = 9\n",
    "top_movies = top_5_rated_movies(user_id, merged_data)\n",
    "\n",
    "print(f\"Top 5 rated movies for User {user_id}:\\n\", top_movies)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
